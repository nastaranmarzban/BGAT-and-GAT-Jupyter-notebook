{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Mount to gdrive to read data, adjacency matrix, p_link and labels. "
      ],
      "metadata": {
        "id": "2u2_tDSmOVz2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtqKkhhMec_7",
        "outputId": "087f8e38-e957-4340-b37a-8e74f63d0c46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install pandas to read csv files from gdrive. Install torch and numpy which are packages that are needed durind coding."
      ],
      "metadata": {
        "id": "J2RAEkgGOeNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DCS47CeemPc",
        "outputId": "bab9da2a-dc1d-4afb-fd3e-00582b1bb686"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.6)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data which are processed in preprocessing_data_cancer.ipynb file."
      ],
      "metadata": {
        "id": "SBpOh_OROpi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = F\"/gdrive/MyDrive/Cancer/cancer.pt\"\n",
        "Data = torch.load(path)\n",
        "Data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXVSW1eveo1m",
        "outputId": "722c3884-4c2b-4768-ea14-2815453bd5b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'x': tensor([[1.7990e+01, 1.0380e+01, 1.2280e+02,  ..., 2.6540e-01, 4.6010e-01,\n",
              "          1.1890e-01],\n",
              "         [2.0570e+01, 1.7770e+01, 1.3290e+02,  ..., 1.8600e-01, 2.7500e-01,\n",
              "          8.9020e-02],\n",
              "         [1.9690e+01, 2.1250e+01, 1.3000e+02,  ..., 2.4300e-01, 3.6130e-01,\n",
              "          8.7580e-02],\n",
              "         ...,\n",
              "         [1.3030e+01, 1.8420e+01, 8.2610e+01,  ..., 5.0130e-02, 1.9870e-01,\n",
              "          6.1690e-02],\n",
              "         [1.3080e+01, 1.5710e+01, 8.5630e+01,  ..., 7.2830e-02, 3.1840e-01,\n",
              "          8.1830e-02],\n",
              "         [9.5040e+00, 1.2440e+01, 6.0340e+01,  ..., 6.2270e-02, 2.4500e-01,\n",
              "          7.7730e-02]]), 'edge_index': tensor([[ 0,  0,  0,  ..., 79, 79, 79],\n",
              "         [ 2,  3,  4,  ..., 72, 74, 76]]), 'y': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1]), 'train_mask': tensor([False, False,  True, False,  True, False, False, False, False, False,\n",
              "          True,  True, False, False, False,  True, False, False, False, False,\n",
              "         False, False,  True, False, False,  True, False,  True, False,  True,\n",
              "          True, False, False, False, False, False, False, False, False,  True,\n",
              "         False, False,  True,  True, False, False, False, False, False, False,\n",
              "         False, False, False, False,  True, False,  True, False, False, False,\n",
              "         False, False,  True, False,  True,  True,  True, False, False, False,\n",
              "         False, False, False, False,  True, False,  True, False,  True, False]), 'val_mask': tensor([False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False,  True, False,\n",
              "          True, False, False, False, False, False, False, False,  True, False,\n",
              "         False, False, False, False, False,  True, False,  True, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False,  True,  True, False, False, False, False,  True, False,\n",
              "         False, False, False, False, False, False, False,  True, False, False,\n",
              "         False, False, False,  True, False, False, False, False, False, False]), 'test_mask': tensor([ True,  True, False,  True, False,  True,  True,  True,  True,  True,\n",
              "         False, False,  True,  True,  True, False,  True,  True, False,  True,\n",
              "         False,  True, False,  True,  True, False,  True, False, False, False,\n",
              "         False,  True,  True,  True,  True, False,  True, False,  True, False,\n",
              "          True,  True, False, False,  True,  True,  True,  True,  True,  True,\n",
              "          True,  True, False, False, False,  True, False,  True, False,  True,\n",
              "          True,  True, False,  True, False, False, False, False,  True,  True,\n",
              "          True,  True,  True, False, False,  True, False,  True, False,  True])}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = F\"/gdrive/MyDrive/Cancer/p_links_cancer.pt\"\n",
        "p_link = torch.load(path)\n",
        "print(p_link.size())\n",
        "print(p_link.dtype)\n",
        "print(p_link.type())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_xN_Thqewd5",
        "outputId": "35c238eb-d5ad-4583-d4f1-6cf7e0c5141d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([80, 80])\n",
            "torch.float32\n",
            "torch.FloatTensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install torch_geometic."
      ],
      "metadata": {
        "id": "S6zPBPzPPGXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NM3FXiW_fJfo",
        "outputId": "4837dc34-e4cd-463b-ed14-f3e3403f949d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.0+cu116\n",
            "\u001b[K     |████████████████████████████████| 9.4 MB 8.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 8.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 280 kB 8.7 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create BGAT and GAT layers. "
      ],
      "metadata": {
        "id": "62OacUI0PNR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import MessagePassing\n",
        "import torch_geometric.nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.utils import add_self_loops\n",
        "from torch_geometric.nn import GATConv"
      ],
      "metadata": {
        "id": "WT2iDYEtfM6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BGATConv(MessagePassing):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        out_channels,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        kwargs.setdefault('aggr', 'add')\n",
        "        super().__init__(node_dim = 0, **kwargs)\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        edge_index, _ = add_self_loops(Data[\"edge_index\"], num_nodes = Data[\"x\"].size(0))\n",
        "        x = self.lin(x)\n",
        "        atten = p_link\n",
        "        return self.propagate(edge_index, x=x, atten = atten)\n",
        "\n",
        "    def message(self, x_j, atten, edge_index_i, edge_index_j):\n",
        "        return atten[edge_index_i, edge_index_j].reshape(-1,1) * x_j\n",
        "\n",
        "    def __repr__(self):\n",
        "        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels, self.out_channels)"
      ],
      "metadata": {
        "id": "NaQQHerIfQ0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Myconv_BGAT(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        torch.manual_seed(2)\n",
        "        self.conv1 = BGATConv(in_channels = 30, out_channels = 15)\n",
        "        self.conv2 =  BGATConv(15, 2)\n",
        "        \n",
        "    def forward(self, x, edge_index):\n",
        "        h = self.conv1(x, edge_index)\n",
        "        h = F.torch.tanh(h)\n",
        "        h = self.conv2(h, edge_index)\n",
        "        h = F.log_softmax(h)\n",
        "        return h\n",
        "        \n",
        "model_BGAT = Myconv_BGAT()\n",
        "print(model_BGAT)\n",
        "print(model_BGAT.forward(Data[\"x\"], Data[\"edge_index\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8VSb94MfUHH",
        "outputId": "a2312aff-5590-4bc7-bbc3-11d6940ab2a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Myconv_BGAT(\n",
            "  (conv1): BGATConv(30, 15)\n",
            "  (conv2): BGATConv(15, 2)\n",
            ")\n",
            "tensor([[-5.8928e+00, -2.7629e-03],\n",
            "        [-6.2349e+00, -1.9617e-03],\n",
            "        [-5.5977e+00, -3.7133e-03],\n",
            "        [-5.5730e+00, -3.8061e-03],\n",
            "        [-3.9700e+00, -1.9054e-02],\n",
            "        [-4.8565e+00, -7.8078e-03],\n",
            "        [-6.3340e+00, -1.7764e-03],\n",
            "        [-6.5407e+00, -1.4446e-03],\n",
            "        [-5.6902e+00, -3.3845e-03],\n",
            "        [-5.2904e+00, -5.0525e-03],\n",
            "        [-6.6747e+00, -1.2633e-03],\n",
            "        [-6.8860e+00, -1.0225e-03],\n",
            "        [-4.6494e+00, -9.6129e-03],\n",
            "        [-4.3784e+00, -1.2625e-02],\n",
            "        [-6.3528e+00, -1.7433e-03],\n",
            "        [-6.0144e+00, -2.4463e-03],\n",
            "        [-5.7492e+00, -3.1905e-03],\n",
            "        [-5.3906e+00, -4.5698e-03],\n",
            "        [-2.9897e+00, -5.1612e-02],\n",
            "        [-7.3064e+00, -6.7152e-04],\n",
            "        [-7.0723e+00, -8.4865e-04],\n",
            "        [-5.3999e+00, -4.5273e-03],\n",
            "        [-6.2035e+00, -2.0243e-03],\n",
            "        [-6.8066e+00, -1.1071e-03],\n",
            "        [-6.6792e+00, -1.2576e-03],\n",
            "        [-7.2586e+00, -7.0428e-04],\n",
            "        [-3.1390e+00, -4.4295e-02],\n",
            "        [-4.9486e+00, -7.1185e-03],\n",
            "        [-6.0178e+00, -2.4380e-03],\n",
            "        [-4.2690e+00, -1.4094e-02],\n",
            "        [-7.1542e+00, -7.8183e-04],\n",
            "        [-7.3655e+00, -6.3292e-04],\n",
            "        [-4.5126e+00, -1.1030e-02],\n",
            "        [-7.0823e+00, -8.4019e-04],\n",
            "        [-2.4236e+00, -9.2771e-02],\n",
            "        [-6.1994e+00, -2.0328e-03],\n",
            "        [-7.9144e+00, -3.6555e-04],\n",
            "        [-4.8018e+00, -8.2487e-03],\n",
            "        [-6.6140e+00, -1.3423e-03],\n",
            "        [-7.2654e+00, -6.9951e-04],\n",
            "        [-3.4357e+00, -3.2734e-02],\n",
            "        [-5.2732e+00, -5.1405e-03],\n",
            "        [-4.1446e+00, -1.5977e-02],\n",
            "        [-7.7225e+00, -4.4288e-04],\n",
            "        [-5.4440e+00, -4.3317e-03],\n",
            "        [-6.6199e+00, -1.3345e-03],\n",
            "        [-6.6428e+00, -1.3041e-03],\n",
            "        [-3.6934e+00, -2.5201e-02],\n",
            "        [-3.5118e+00, -3.0297e-02],\n",
            "        [-5.3416e+00, -4.7999e-03],\n",
            "        [-5.8156e+00, -2.9852e-03],\n",
            "        [-5.3097e+00, -4.9555e-03],\n",
            "        [-5.4658e+00, -4.2378e-03],\n",
            "        [-5.5847e+00, -3.7620e-03],\n",
            "        [-4.6889e+00, -9.2398e-03],\n",
            "        [-8.8120e+00, -1.4900e-04],\n",
            "        [-8.5314e+00, -1.9715e-04],\n",
            "        [-5.5288e+00, -3.9786e-03],\n",
            "        [-3.4525e+00, -3.2178e-02],\n",
            "        [-5.5740e+00, -3.8025e-03],\n",
            "        [-5.5637e+00, -3.8418e-03],\n",
            "        [-6.9040e+00, -1.0043e-03],\n",
            "        [-4.3241e+00, -1.3334e-02],\n",
            "        [-4.3995e+00, -1.2359e-02],\n",
            "        [-5.7040e+00, -3.3381e-03],\n",
            "        [-8.4931e+00, -2.0490e-04],\n",
            "        [-5.4031e+00, -4.5126e-03],\n",
            "        [-6.0171e+00, -2.4397e-03],\n",
            "        [-4.8123e+00, -8.1620e-03],\n",
            "        [-2.5719e+00, -7.9468e-02],\n",
            "        [-5.6762e+00, -3.4326e-03],\n",
            "        [-2.4232e+00, -9.2814e-02],\n",
            "        [-6.4859e+00, -1.5260e-03],\n",
            "        [-7.5738e+00, -5.1390e-04],\n",
            "        [-3.1442e+00, -4.4056e-02],\n",
            "        [-4.4286e+00, -1.2003e-02],\n",
            "        [-6.5660e+00, -1.4084e-03],\n",
            "        [-4.8862e+00, -7.5788e-03],\n",
            "        [-6.7863e+00, -1.1297e-03],\n",
            "        [-8.5275e+00, -1.9799e-04]], grad_fn=<LogSoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-b75922bbf427>:12: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  h = F.log_softmax(h)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Myconv_GAT(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        torch.manual_seed(2)\n",
        "        self.conv1 = GATConv(in_channels = 30, out_channels = 30)\n",
        "        self.conv2 =  GATConv(30, 10)\n",
        "        self.conv3 =  GATConv(10, 2)\n",
        "        \n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        f = self.conv1(x, edge_index)\n",
        "        f = F.torch.tanh(f)\n",
        "        f = self.conv2(f, edge_index)\n",
        "        f = F.torch.tanh(f)\n",
        "        f = self.conv3(f, edge_index)# Final GNN embedding space.\n",
        "        f = F.torch.tanh(f)\n",
        "        return f\n",
        "        \n",
        "\n",
        "model_GAT = Myconv_GAT()\n",
        "print(model_GAT)\n",
        "print(model_GAT.forward(Data[\"x\"], Data[\"edge_index\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B78_Dzbtfe8o",
        "outputId": "bba40d79-fd33-4178-a3bd-45cc82d12a66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Myconv_GAT(\n",
            "  (conv1): GATConv(30, 30, heads=1)\n",
            "  (conv2): GATConv(30, 10, heads=1)\n",
            "  (conv3): GATConv(10, 2, heads=1)\n",
            ")\n",
            "tensor([[ 0.9850, -0.3719],\n",
            "        [ 0.9852, -0.3369],\n",
            "        [ 0.9836, -0.3399],\n",
            "        [ 0.9850, -0.3725],\n",
            "        [ 0.9855, -0.3528],\n",
            "        [ 0.9839, -0.3196],\n",
            "        [ 0.9857, -0.3511],\n",
            "        [ 0.9849, -0.3387],\n",
            "        [ 0.9852, -0.3534],\n",
            "        [ 0.9844, -0.3152],\n",
            "        [ 0.9848, -0.3064],\n",
            "        [ 0.9853, -0.3682],\n",
            "        [ 0.9842, -0.2949],\n",
            "        [ 0.9850, -0.3705],\n",
            "        [ 0.9853, -0.3580],\n",
            "        [ 0.9846, -0.3157],\n",
            "        [ 0.9843, -0.3241],\n",
            "        [ 0.9846, -0.3457],\n",
            "        [ 0.9848, -0.3468],\n",
            "        [ 0.9848, -0.3366],\n",
            "        [ 0.9853, -0.3621],\n",
            "        [ 0.9854, -0.3462],\n",
            "        [ 0.9852, -0.3531],\n",
            "        [ 0.9845, -0.3353],\n",
            "        [ 0.9849, -0.3458],\n",
            "        [ 0.9851, -0.3621],\n",
            "        [ 0.9829, -0.2771],\n",
            "        [ 0.9860, -0.3540],\n",
            "        [ 0.9849, -0.3438],\n",
            "        [ 0.9857, -0.3436],\n",
            "        [ 0.9843, -0.3232],\n",
            "        [ 0.9853, -0.3633],\n",
            "        [ 0.9850, -0.3014],\n",
            "        [ 0.9851, -0.3457],\n",
            "        [ 0.9834, -0.2803],\n",
            "        [ 0.9843, -0.3411],\n",
            "        [ 0.9848, -0.3263],\n",
            "        [ 0.9853, -0.3233],\n",
            "        [ 0.9849, -0.3586],\n",
            "        [ 0.9851, -0.3421],\n",
            "        [ 0.9848, -0.3089],\n",
            "        [ 0.9845, -0.3037],\n",
            "        [ 0.9854, -0.3517],\n",
            "        [ 0.9838, -0.3099],\n",
            "        [ 0.9848, -0.3076],\n",
            "        [ 0.9844, -0.3351],\n",
            "        [ 0.9853, -0.3359],\n",
            "        [ 0.9830, -0.2967],\n",
            "        [ 0.9835, -0.3009],\n",
            "        [ 0.9852, -0.3406],\n",
            "        [ 0.9849, -0.3496],\n",
            "        [ 0.9851, -0.3212],\n",
            "        [ 0.9850, -0.3050],\n",
            "        [ 0.9846, -0.3378],\n",
            "        [ 0.9833, -0.2827],\n",
            "        [ 0.9848, -0.3646],\n",
            "        [ 0.9847, -0.3576],\n",
            "        [ 0.9848, -0.3361],\n",
            "        [ 0.9838, -0.3062],\n",
            "        [ 0.9847, -0.3463],\n",
            "        [ 0.9850, -0.3269],\n",
            "        [ 0.9840, -0.3019],\n",
            "        [ 0.9856, -0.3475],\n",
            "        [ 0.9859, -0.3293],\n",
            "        [ 0.9854, -0.3519],\n",
            "        [ 0.9841, -0.3296],\n",
            "        [ 0.9851, -0.3523],\n",
            "        [ 0.9842, -0.3395],\n",
            "        [ 0.9839, -0.2994],\n",
            "        [ 0.9835, -0.2918],\n",
            "        [ 0.9851, -0.3169],\n",
            "        [ 0.9833, -0.3218],\n",
            "        [ 0.9851, -0.3628],\n",
            "        [ 0.9854, -0.3506],\n",
            "        [ 0.9824, -0.2399],\n",
            "        [ 0.9857, -0.3724],\n",
            "        [ 0.9849, -0.3478],\n",
            "        [ 0.9851, -0.3539],\n",
            "        [ 0.9847, -0.3497],\n",
            "        [ 0.9850, -0.3106]], grad_fn=<TanhBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train BGAT and GAT models. "
      ],
      "metadata": {
        "id": "iLB3eFB9PdUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Myconv_BGAT()\n",
        "criterion = torch.nn.CrossEntropyLoss()  # Define loss criterion.\n",
        "optimizer = torch.optim.Adam(model.parameters(),  lr = 0.0005)  # Define optimizer, an object for updating parameters\n",
        "#loss = loss + weight decay parameter * L2 norm of the weights, 1) To prevent overfitting 2) To keep the weights small and avoid exploding gradient\n",
        "\n",
        "def train_BGAT(Data):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()  # Clear gradients.\n",
        "    out = model(Data[\"x\"], Data[\"edge_index\"])\n",
        "    train_loss_BGAT = criterion(out[Data[\"train_mask\"]], Data[\"y\"][Data[\"train_mask\"]])  # Compute the loss solely based on the training nodes.\n",
        "    train_loss_BGAT.backward()  # Derive gradients.\n",
        "    optimizer.step()  # Update parameters based on gradients.\n",
        "    return train_loss_BGAT\n",
        "\n",
        "train_loss_BGAT_ = []\n",
        "for epoch in range(1, 201):\n",
        "  epoch_train_lossBGAT = []\n",
        "  train_loss_BGAT = train_BGAT(Data)\n",
        "  epoch_train_lossBGAT.append(train_loss_BGAT.item())\n",
        "  train_loss_BGAT_.append(sum(epoch_train_lossBGAT)/len(epoch_train_lossBGAT))\n",
        "  print(f'Train_BGAT:  {train_loss_BGAT:.3f}') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwrfUrr-fqNP",
        "outputId": "71248928-72e4-4109-d776-d5b7f73ab52d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train_BGAT:  3.015\n",
            "Train_BGAT:  1.955\n",
            "Train_BGAT:  1.004\n",
            "Train_BGAT:  0.650\n",
            "Train_BGAT:  0.660\n",
            "Train_BGAT:  0.701\n",
            "Train_BGAT:  0.699\n",
            "Train_BGAT:  0.747\n",
            "Train_BGAT:  0.736\n",
            "Train_BGAT:  0.705\n",
            "Train_BGAT:  0.697\n",
            "Train_BGAT:  0.686\n",
            "Train_BGAT:  0.664\n",
            "Train_BGAT:  0.648\n",
            "Train_BGAT:  0.641\n",
            "Train_BGAT:  0.639\n",
            "Train_BGAT:  0.637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-b75922bbf427>:12: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  h = F.log_softmax(h)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train_BGAT:  0.640\n",
            "Train_BGAT:  0.640\n",
            "Train_BGAT:  0.636\n",
            "Train_BGAT:  0.624\n",
            "Train_BGAT:  0.620\n",
            "Train_BGAT:  0.620\n",
            "Train_BGAT:  0.619\n",
            "Train_BGAT:  0.616\n",
            "Train_BGAT:  0.607\n",
            "Train_BGAT:  0.603\n",
            "Train_BGAT:  0.601\n",
            "Train_BGAT:  0.599\n",
            "Train_BGAT:  0.600\n",
            "Train_BGAT:  0.600\n",
            "Train_BGAT:  0.600\n",
            "Train_BGAT:  0.600\n",
            "Train_BGAT:  0.599\n",
            "Train_BGAT:  0.598\n",
            "Train_BGAT:  0.596\n",
            "Train_BGAT:  0.596\n",
            "Train_BGAT:  0.595\n",
            "Train_BGAT:  0.594\n",
            "Train_BGAT:  0.593\n",
            "Train_BGAT:  0.592\n",
            "Train_BGAT:  0.590\n",
            "Train_BGAT:  0.589\n",
            "Train_BGAT:  0.588\n",
            "Train_BGAT:  0.586\n",
            "Train_BGAT:  0.585\n",
            "Train_BGAT:  0.584\n",
            "Train_BGAT:  0.583\n",
            "Train_BGAT:  0.582\n",
            "Train_BGAT:  0.581\n",
            "Train_BGAT:  0.580\n",
            "Train_BGAT:  0.579\n",
            "Train_BGAT:  0.577\n",
            "Train_BGAT:  0.574\n",
            "Train_BGAT:  0.572\n",
            "Train_BGAT:  0.571\n",
            "Train_BGAT:  0.570\n",
            "Train_BGAT:  0.569\n",
            "Train_BGAT:  0.569\n",
            "Train_BGAT:  0.568\n",
            "Train_BGAT:  0.568\n",
            "Train_BGAT:  0.567\n",
            "Train_BGAT:  0.565\n",
            "Train_BGAT:  0.564\n",
            "Train_BGAT:  0.563\n",
            "Train_BGAT:  0.562\n",
            "Train_BGAT:  0.561\n",
            "Train_BGAT:  0.560\n",
            "Train_BGAT:  0.559\n",
            "Train_BGAT:  0.559\n",
            "Train_BGAT:  0.558\n",
            "Train_BGAT:  0.557\n",
            "Train_BGAT:  0.556\n",
            "Train_BGAT:  0.555\n",
            "Train_BGAT:  0.554\n",
            "Train_BGAT:  0.554\n",
            "Train_BGAT:  0.553\n",
            "Train_BGAT:  0.552\n",
            "Train_BGAT:  0.552\n",
            "Train_BGAT:  0.551\n",
            "Train_BGAT:  0.550\n",
            "Train_BGAT:  0.549\n",
            "Train_BGAT:  0.549\n",
            "Train_BGAT:  0.548\n",
            "Train_BGAT:  0.547\n",
            "Train_BGAT:  0.547\n",
            "Train_BGAT:  0.546\n",
            "Train_BGAT:  0.545\n",
            "Train_BGAT:  0.544\n",
            "Train_BGAT:  0.544\n",
            "Train_BGAT:  0.543\n",
            "Train_BGAT:  0.543\n",
            "Train_BGAT:  0.542\n",
            "Train_BGAT:  0.541\n",
            "Train_BGAT:  0.541\n",
            "Train_BGAT:  0.540\n",
            "Train_BGAT:  0.539\n",
            "Train_BGAT:  0.539\n",
            "Train_BGAT:  0.538\n",
            "Train_BGAT:  0.538\n",
            "Train_BGAT:  0.537\n",
            "Train_BGAT:  0.537\n",
            "Train_BGAT:  0.536\n",
            "Train_BGAT:  0.535\n",
            "Train_BGAT:  0.535\n",
            "Train_BGAT:  0.534\n",
            "Train_BGAT:  0.534\n",
            "Train_BGAT:  0.533\n",
            "Train_BGAT:  0.533\n",
            "Train_BGAT:  0.532\n",
            "Train_BGAT:  0.532\n",
            "Train_BGAT:  0.531\n",
            "Train_BGAT:  0.531\n",
            "Train_BGAT:  0.530\n",
            "Train_BGAT:  0.530\n",
            "Train_BGAT:  0.529\n",
            "Train_BGAT:  0.529\n",
            "Train_BGAT:  0.528\n",
            "Train_BGAT:  0.528\n",
            "Train_BGAT:  0.527\n",
            "Train_BGAT:  0.527\n",
            "Train_BGAT:  0.526\n",
            "Train_BGAT:  0.526\n",
            "Train_BGAT:  0.525\n",
            "Train_BGAT:  0.525\n",
            "Train_BGAT:  0.525\n",
            "Train_BGAT:  0.524\n",
            "Train_BGAT:  0.524\n",
            "Train_BGAT:  0.523\n",
            "Train_BGAT:  0.523\n",
            "Train_BGAT:  0.523\n",
            "Train_BGAT:  0.522\n",
            "Train_BGAT:  0.522\n",
            "Train_BGAT:  0.521\n",
            "Train_BGAT:  0.521\n",
            "Train_BGAT:  0.521\n",
            "Train_BGAT:  0.520\n",
            "Train_BGAT:  0.520\n",
            "Train_BGAT:  0.519\n",
            "Train_BGAT:  0.519\n",
            "Train_BGAT:  0.519\n",
            "Train_BGAT:  0.518\n",
            "Train_BGAT:  0.518\n",
            "Train_BGAT:  0.518\n",
            "Train_BGAT:  0.517\n",
            "Train_BGAT:  0.517\n",
            "Train_BGAT:  0.517\n",
            "Train_BGAT:  0.516\n",
            "Train_BGAT:  0.516\n",
            "Train_BGAT:  0.516\n",
            "Train_BGAT:  0.515\n",
            "Train_BGAT:  0.515\n",
            "Train_BGAT:  0.515\n",
            "Train_BGAT:  0.514\n",
            "Train_BGAT:  0.514\n",
            "Train_BGAT:  0.514\n",
            "Train_BGAT:  0.514\n",
            "Train_BGAT:  0.513\n",
            "Train_BGAT:  0.513\n",
            "Train_BGAT:  0.513\n",
            "Train_BGAT:  0.512\n",
            "Train_BGAT:  0.512\n",
            "Train_BGAT:  0.512\n",
            "Train_BGAT:  0.512\n",
            "Train_BGAT:  0.511\n",
            "Train_BGAT:  0.511\n",
            "Train_BGAT:  0.511\n",
            "Train_BGAT:  0.511\n",
            "Train_BGAT:  0.510\n",
            "Train_BGAT:  0.510\n",
            "Train_BGAT:  0.510\n",
            "Train_BGAT:  0.510\n",
            "Train_BGAT:  0.509\n",
            "Train_BGAT:  0.509\n",
            "Train_BGAT:  0.509\n",
            "Train_BGAT:  0.509\n",
            "Train_BGAT:  0.508\n",
            "Train_BGAT:  0.508\n",
            "Train_BGAT:  0.508\n",
            "Train_BGAT:  0.508\n",
            "Train_BGAT:  0.508\n",
            "Train_BGAT:  0.507\n",
            "Train_BGAT:  0.507\n",
            "Train_BGAT:  0.507\n",
            "Train_BGAT:  0.507\n",
            "Train_BGAT:  0.507\n",
            "Train_BGAT:  0.506\n",
            "Train_BGAT:  0.506\n",
            "Train_BGAT:  0.506\n",
            "Train_BGAT:  0.506\n",
            "Train_BGAT:  0.506\n",
            "Train_BGAT:  0.505\n",
            "Train_BGAT:  0.505\n",
            "Train_BGAT:  0.505\n",
            "Train_BGAT:  0.505\n",
            "Train_BGAT:  0.505\n",
            "Train_BGAT:  0.504\n",
            "Train_BGAT:  0.504\n",
            "Train_BGAT:  0.504\n",
            "Train_BGAT:  0.504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Myconv_GAT()\n",
        "criterion = torch.nn.CrossEntropyLoss()  # Define loss criterion.\n",
        "optimizer = torch.optim.Adam(model.parameters(),  lr = 0.0005, weight_decay = 5e-4)  # Define optimizer, an object for updating parameters\n",
        "#loss = loss + weight decay parameter * L2 norm of the weights, 1) To prevent overfitting 2) To keep the weights small and avoid exploding gradient\n",
        "\n",
        "def train_GAT(Data):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()  # Clear gradients.\n",
        "    out = model(Data[\"x\"], Data[\"edge_index\"])\n",
        "    train_loss_GAT = criterion(out[Data[\"train_mask\"]], Data[\"y\"][Data[\"train_mask\"]])  # Compute the loss solely based on the training nodes.\n",
        "    train_loss_GAT.backward()  # Derive gradients.\n",
        "    optimizer.step()  # Update parameters based on gradients.\n",
        "    return train_loss_GAT\n",
        "\n",
        "train_loss_GAT_ = []\n",
        "for epoch in range(1, 201):\n",
        "  epoch_train_lossGAT = []\n",
        "  train_loss_GAT = train_GAT(Data)\n",
        "  epoch_train_lossGAT.append(train_loss_GAT.item())\n",
        "  train_loss_GAT_.append(sum(epoch_train_lossGAT)/len(epoch_train_lossGAT))\n",
        "  print(f'Train_GAT:  {train_loss_GAT:.3f}') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVlWYojlfsuq",
        "outputId": "d1eaf7c8-1d55-472b-9091-4a97139ef23f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train_GAT:  0.894\n",
            "Train_GAT:  0.883\n",
            "Train_GAT:  0.874\n",
            "Train_GAT:  0.863\n",
            "Train_GAT:  0.850\n",
            "Train_GAT:  0.835\n",
            "Train_GAT:  0.823\n",
            "Train_GAT:  0.813\n",
            "Train_GAT:  0.802\n",
            "Train_GAT:  0.789\n",
            "Train_GAT:  0.776\n",
            "Train_GAT:  0.769\n",
            "Train_GAT:  0.762\n",
            "Train_GAT:  0.754\n",
            "Train_GAT:  0.747\n",
            "Train_GAT:  0.741\n",
            "Train_GAT:  0.736\n",
            "Train_GAT:  0.730\n",
            "Train_GAT:  0.724\n",
            "Train_GAT:  0.719\n",
            "Train_GAT:  0.715\n",
            "Train_GAT:  0.711\n",
            "Train_GAT:  0.708\n",
            "Train_GAT:  0.706\n",
            "Train_GAT:  0.703\n",
            "Train_GAT:  0.702\n",
            "Train_GAT:  0.700\n",
            "Train_GAT:  0.698\n",
            "Train_GAT:  0.697\n",
            "Train_GAT:  0.696\n",
            "Train_GAT:  0.694\n",
            "Train_GAT:  0.693\n",
            "Train_GAT:  0.692\n",
            "Train_GAT:  0.692\n",
            "Train_GAT:  0.691\n",
            "Train_GAT:  0.690\n",
            "Train_GAT:  0.689\n",
            "Train_GAT:  0.688\n",
            "Train_GAT:  0.687\n",
            "Train_GAT:  0.687\n",
            "Train_GAT:  0.686\n",
            "Train_GAT:  0.686\n",
            "Train_GAT:  0.686\n",
            "Train_GAT:  0.685\n",
            "Train_GAT:  0.685\n",
            "Train_GAT:  0.685\n",
            "Train_GAT:  0.685\n",
            "Train_GAT:  0.684\n",
            "Train_GAT:  0.684\n",
            "Train_GAT:  0.684\n",
            "Train_GAT:  0.684\n",
            "Train_GAT:  0.684\n",
            "Train_GAT:  0.684\n",
            "Train_GAT:  0.684\n",
            "Train_GAT:  0.683\n",
            "Train_GAT:  0.683\n",
            "Train_GAT:  0.683\n",
            "Train_GAT:  0.683\n",
            "Train_GAT:  0.683\n",
            "Train_GAT:  0.683\n",
            "Train_GAT:  0.683\n",
            "Train_GAT:  0.683\n",
            "Train_GAT:  0.683\n",
            "Train_GAT:  0.683\n",
            "Train_GAT:  0.683\n",
            "Train_GAT:  0.682\n",
            "Train_GAT:  0.682\n",
            "Train_GAT:  0.682\n",
            "Train_GAT:  0.682\n",
            "Train_GAT:  0.682\n",
            "Train_GAT:  0.682\n",
            "Train_GAT:  0.682\n",
            "Train_GAT:  0.680\n",
            "Train_GAT:  0.680\n",
            "Train_GAT:  0.679\n",
            "Train_GAT:  0.679\n",
            "Train_GAT:  0.676\n",
            "Train_GAT:  0.675\n",
            "Train_GAT:  0.672\n",
            "Train_GAT:  0.672\n",
            "Train_GAT:  0.671\n",
            "Train_GAT:  0.674\n",
            "Train_GAT:  0.672\n",
            "Train_GAT:  0.669\n",
            "Train_GAT:  0.668\n",
            "Train_GAT:  0.668\n",
            "Train_GAT:  0.667\n",
            "Train_GAT:  0.667\n",
            "Train_GAT:  0.667\n",
            "Train_GAT:  0.666\n",
            "Train_GAT:  0.666\n",
            "Train_GAT:  0.665\n",
            "Train_GAT:  0.664\n",
            "Train_GAT:  0.663\n",
            "Train_GAT:  0.662\n",
            "Train_GAT:  0.661\n",
            "Train_GAT:  0.660\n",
            "Train_GAT:  0.659\n",
            "Train_GAT:  0.658\n",
            "Train_GAT:  0.657\n",
            "Train_GAT:  0.656\n",
            "Train_GAT:  0.655\n",
            "Train_GAT:  0.654\n",
            "Train_GAT:  0.652\n",
            "Train_GAT:  0.651\n",
            "Train_GAT:  0.650\n",
            "Train_GAT:  0.648\n",
            "Train_GAT:  0.646\n",
            "Train_GAT:  0.645\n",
            "Train_GAT:  0.643\n",
            "Train_GAT:  0.641\n",
            "Train_GAT:  0.639\n",
            "Train_GAT:  0.637\n",
            "Train_GAT:  0.635\n",
            "Train_GAT:  0.633\n",
            "Train_GAT:  0.630\n",
            "Train_GAT:  0.628\n",
            "Train_GAT:  0.626\n",
            "Train_GAT:  0.624\n",
            "Train_GAT:  0.622\n",
            "Train_GAT:  0.620\n",
            "Train_GAT:  0.618\n",
            "Train_GAT:  0.615\n",
            "Train_GAT:  0.613\n",
            "Train_GAT:  0.611\n",
            "Train_GAT:  0.608\n",
            "Train_GAT:  0.606\n",
            "Train_GAT:  0.604\n",
            "Train_GAT:  0.602\n",
            "Train_GAT:  0.599\n",
            "Train_GAT:  0.597\n",
            "Train_GAT:  0.595\n",
            "Train_GAT:  0.593\n",
            "Train_GAT:  0.591\n",
            "Train_GAT:  0.588\n",
            "Train_GAT:  0.586\n",
            "Train_GAT:  0.584\n",
            "Train_GAT:  0.582\n",
            "Train_GAT:  0.580\n",
            "Train_GAT:  0.578\n",
            "Train_GAT:  0.576\n",
            "Train_GAT:  0.574\n",
            "Train_GAT:  0.572\n",
            "Train_GAT:  0.570\n",
            "Train_GAT:  0.568\n",
            "Train_GAT:  0.567\n",
            "Train_GAT:  0.565\n",
            "Train_GAT:  0.563\n",
            "Train_GAT:  0.562\n",
            "Train_GAT:  0.560\n",
            "Train_GAT:  0.559\n",
            "Train_GAT:  0.557\n",
            "Train_GAT:  0.556\n",
            "Train_GAT:  0.554\n",
            "Train_GAT:  0.553\n",
            "Train_GAT:  0.551\n",
            "Train_GAT:  0.550\n",
            "Train_GAT:  0.549\n",
            "Train_GAT:  0.548\n",
            "Train_GAT:  0.546\n",
            "Train_GAT:  0.545\n",
            "Train_GAT:  0.544\n",
            "Train_GAT:  0.543\n",
            "Train_GAT:  0.542\n",
            "Train_GAT:  0.540\n",
            "Train_GAT:  0.539\n",
            "Train_GAT:  0.538\n",
            "Train_GAT:  0.537\n",
            "Train_GAT:  0.536\n",
            "Train_GAT:  0.535\n",
            "Train_GAT:  0.534\n",
            "Train_GAT:  0.533\n",
            "Train_GAT:  0.532\n",
            "Train_GAT:  0.531\n",
            "Train_GAT:  0.530\n",
            "Train_GAT:  0.529\n",
            "Train_GAT:  0.528\n",
            "Train_GAT:  0.527\n",
            "Train_GAT:  0.526\n",
            "Train_GAT:  0.525\n",
            "Train_GAT:  0.524\n",
            "Train_GAT:  0.524\n",
            "Train_GAT:  0.523\n",
            "Train_GAT:  0.522\n",
            "Train_GAT:  0.521\n",
            "Train_GAT:  0.520\n",
            "Train_GAT:  0.519\n",
            "Train_GAT:  0.518\n",
            "Train_GAT:  0.518\n",
            "Train_GAT:  0.517\n",
            "Train_GAT:  0.516\n",
            "Train_GAT:  0.515\n",
            "Train_GAT:  0.514\n",
            "Train_GAT:  0.514\n",
            "Train_GAT:  0.513\n",
            "Train_GAT:  0.512\n",
            "Train_GAT:  0.511\n",
            "Train_GAT:  0.511\n",
            "Train_GAT:  0.510\n",
            "Train_GAT:  0.509\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize train_loss for both models. "
      ],
      "metadata": {
        "id": "44ZeVjjVPikX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_loss_BGAT_, \"m\")\n",
        "plt.plot(train_loss_GAT_, \"c\")\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['Train_BGAT','Train_GAT'])\n",
        "plt.title('Breast cancer dataset, Train_BGAT vs Train_GAT ')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "NjggHz5ZfvX-",
        "outputId": "8a8e8233-1f57-4932-a1ef-993d0db2c312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}