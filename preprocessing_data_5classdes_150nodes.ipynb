{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdnULG3Qfhue08SMi+pIBn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nastaranmarzban/BGAT-and-GAT-Jupyter-notebook/blob/main/preprocessing_data_5classdes_150nodes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount to gdrive to read data, adjacency matrix, p_link and labels."
      ],
      "metadata": {
        "id": "tIsUELJj_4bX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WGuslen_Khe",
        "outputId": "ab54910f-2ae3-4ce8-ae79-2b77394ee8a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install pandas to read csv files from gdrive. Install torch and numpy which are packages that are needed durind coding."
      ],
      "metadata": {
        "id": "GotpN0sZADcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaFnsq3wAEGh",
        "outputId": "bb747b9c-3766-4f02-a987-c7f4ddc0e4c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## It is time to prepare x, edge_index, y, train_mask and test_mask which are needed for PyG."
      ],
      "metadata": {
        "id": "NigLHzIVANWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step1 (preparing x)**: Read multivariate dataset from gdrive and convert the type to what is needed in PyG."
      ],
      "metadata": {
        "id": "lKJ2tOsYAQdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = pd.read_csv('/gdrive/MyDrive/5classes_150.sim/df150_t.csv', sep = ',',header = None)\n",
        "x = x.astype(np.float32) #try to cast all DataFrame columns to specified numpy.dtype\n",
        "x = torch.tensor(x.values) #convert numpy.dtype to a tensor\n",
        "print(x.sum(dim = 1).unique().size()) #to see if there is a duplicate data in x or not\n",
        "print(x.dtype)\n",
        "print(x.type())\n",
        "print(x.size())\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdX4utTEAN_K",
        "outputId": "920d7fb4-96a3-4eaf-ad1b-9106ee0cec87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([150])\n",
            "torch.float32\n",
            "torch.FloatTensor\n",
            "torch.Size([150, 500])\n",
            "tensor([[-1.1996, -0.5363, -1.0551,  ...,  1.0784, -0.1099,  0.6258],\n",
            "        [ 1.9717,  1.5424,  1.0104,  ..., -0.6536,  2.3499, -0.1438],\n",
            "        [-0.3870,  0.3711, -1.0519,  ..., -0.6554,  2.1013, -0.8379],\n",
            "        ...,\n",
            "        [-1.4236, -1.3652, -1.1248,  ..., -1.0004,  0.0174,  1.6165],\n",
            "        [-0.5597, -2.0122,  0.3641,  ...,  0.2956, -0.0478, -0.5333],\n",
            "        [ 0.5681, -0.7714,  0.7749,  ..., -0.5489, -1.6281,  1.2040]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step2 (preparing edge_index)**: Read adjacency matrix from gdrive and convert the type to what is needed in PyG."
      ],
      "metadata": {
        "id": "mzxYa78oAkAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import coo_matrix\n",
        "edge_index_csv = pd.read_csv('/gdrive/MyDrive/5classes_150.sim/adj_diag_150.csv',sep = ',',header = None)\n",
        "#print(edge_index_csv)\n",
        "edge_index_numpy_ndarry = edge_index_csv.values #convert xlsx file to numpy.ndarry\n",
        "edge_index_coo = coo_matrix(edge_index_numpy_ndarry) #convert symmetric matrix to coo_matrix\n",
        "print(edge_index_coo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sby9n1VHAkoM",
        "outputId": "307f84e2-dbc8-4e00-9661-dccb6ded14c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 21)\t1\n",
            "  (0, 57)\t1\n",
            "  (0, 97)\t1\n",
            "  (1, 21)\t1\n",
            "  (1, 24)\t1\n",
            "  (1, 33)\t1\n",
            "  (1, 47)\t1\n",
            "  (1, 74)\t1\n",
            "  (1, 77)\t1\n",
            "  (1, 116)\t1\n",
            "  (1, 117)\t1\n",
            "  (1, 126)\t1\n",
            "  (1, 145)\t1\n",
            "  (2, 65)\t1\n",
            "  (2, 132)\t1\n",
            "  (2, 148)\t1\n",
            "  (3, 15)\t1\n",
            "  (3, 46)\t1\n",
            "  (3, 61)\t1\n",
            "  (3, 76)\t1\n",
            "  (3, 135)\t1\n",
            "  (4, 29)\t1\n",
            "  (4, 45)\t1\n",
            "  (4, 137)\t1\n",
            "  (5, 17)\t1\n",
            "  :\t:\n",
            "  (145, 116)\t1\n",
            "  (145, 117)\t1\n",
            "  (145, 123)\t1\n",
            "  (145, 130)\t1\n",
            "  (146, 57)\t1\n",
            "  (146, 82)\t1\n",
            "  (146, 97)\t1\n",
            "  (146, 134)\t1\n",
            "  (147, 57)\t1\n",
            "  (147, 93)\t1\n",
            "  (148, 2)\t1\n",
            "  (148, 46)\t1\n",
            "  (148, 49)\t1\n",
            "  (148, 73)\t1\n",
            "  (149, 13)\t1\n",
            "  (149, 20)\t1\n",
            "  (149, 32)\t1\n",
            "  (149, 37)\t1\n",
            "  (149, 41)\t1\n",
            "  (149, 62)\t1\n",
            "  (149, 67)\t1\n",
            "  (149, 88)\t1\n",
            "  (149, 109)\t1\n",
            "  (149, 128)\t1\n",
            "  (149, 141)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edge_index_numpy = np.vstack((edge_index_coo.row, edge_index_coo.col)) #convert coo_matrix to numpy.ndarray\n",
        "edge_index_torch_int32 = torch.from_numpy(edge_index_numpy) #convert numpy.ndarray to torch.int32\n",
        "edge_index = edge_index_torch_int32.to(torch.int64) #convert torch.int32 to torch.long\n",
        "print(edge_index)\n",
        "print(edge_index.dtype)\n",
        "print(edge_index.type())\n",
        "print(edge_index.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABDrPPa4Ao7x",
        "outputId": "116c21f0-366a-4614-b5e2-c5a36851362a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  0,   0,   0,  ..., 149, 149, 149],\n",
            "        [ 21,  57,  97,  ..., 109, 128, 141]])\n",
            "torch.int64\n",
            "torch.LongTensor\n",
            "torch.Size([2, 954])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step3 (preparing y)**: Read labels from gdrive and convert the type to what is needed in PyG."
      ],
      "metadata": {
        "id": "50NMvalxAr4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_csv = pd.read_csv('/gdrive/MyDrive/5classes_150.sim/labels_150.csv',sep = ',',header = None)\n",
        "y = torch.tensor(labels_csv.values)\n",
        "y.resize_((150))\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks2KhAetAshV",
        "outputId": "12582500-8083-4e46-ab16-001c1a1fd997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 1, 3, 4, 4, 1, 0, 4, 4, 2, 4, 3, 1, 0, 2, 4, 2, 1, 3, 0, 0, 1, 2, 1,\n",
            "        1, 2, 3, 0, 2, 4, 2, 1, 0, 0, 0, 3, 0, 0, 1, 1, 3, 0, 0, 1, 1, 4, 4, 1,\n",
            "        3, 4, 0, 4, 3, 3, 3, 3, 4, 2, 2, 2, 4, 4, 3, 2, 1, 3, 3, 0, 3, 0, 4, 4,\n",
            "        0, 0, 1, 2, 4, 1, 0, 4, 1, 3, 2, 0, 0, 4, 1, 3, 0, 4, 2, 2, 3, 2, 4, 3,\n",
            "        3, 2, 1, 4, 4, 2, 4, 2, 0, 0, 4, 2, 3, 0, 0, 3, 1, 4, 3, 1, 1, 1, 1, 3,\n",
            "        2, 1, 2, 4, 1, 0, 1, 3, 0, 2, 1, 3, 3, 2, 2, 4, 3, 4, 2, 3, 0, 0, 2, 3,\n",
            "        1, 1, 2, 2, 4, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step4 (preparing train_mask, test_mask)**: split x and y into train and test set."
      ],
      "metadata": {
        "id": "7sg6q864A1S5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "main_mask, test_mask, y_main, y_test = train_test_split(x, y,  test_size = 15, random_state = 0, shuffle = True, stratify = y)\n",
        "train_mask, val_mask, y_train, y_val = train_test_split(main_mask, y_main,  test_size = 15, random_state = 0, shuffle = True, stratify = y_main)\n",
        "print(train_mask.size())\n",
        "print(val_mask.size())\n",
        "print(test_mask.size())\n",
        "print(train_mask.type())\n",
        "print(y_train.type())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fz2LvXGjA18C",
        "outputId": "5d4d1b1b-3412-4f05-b64b-27148ac56935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([120, 500])\n",
            "torch.Size([15, 500])\n",
            "torch.Size([15, 500])\n",
            "torch.FloatTensor\n",
            "torch.LongTensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## To see how many percent of data belong to each class."
      ],
      "metadata": {
        "id": "BRs8q7t7BXE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels, counts = np.unique(y, return_counts = True)\n",
        "print(counts/float(len(y)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JU6dbqYGBXk6",
        "outputId": "3a30f40a-ffd3-4431-b6bb-17b947cd3bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.2 0.2 0.2 0.2 0.2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels, counts = np.unique(y_train, return_counts = True)\n",
        "print(counts/float(len(y_train)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sud51otsBZpN",
        "outputId": "be58146c-6363-463d-818f-4356019cf396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.2 0.2 0.2 0.2 0.2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels, counts = np.unique(y_test, return_counts = True)\n",
        "print(counts/float(len(y_val)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VONTh75XBeRy",
        "outputId": "53d29b8f-c8ea-4fa1-bb6f-6473ae6cb66d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.2 0.2 0.2 0.2 0.2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels, counts = np.unique(y_test, return_counts = True)\n",
        "print(counts/float(len(y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XGGKw96BgPh",
        "outputId": "66a029ad-3186-413b-cc51-d7bf6a304d41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.2 0.2 0.2 0.2 0.2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing train_mask and test_mask based on PyG."
      ],
      "metadata": {
        "id": "f6AlKMWOBi04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_mask = (x.unsqueeze(0) == train_mask.unsqueeze(1)).all(dim = 2).any(dim = 0)\n",
        "print(train_mask)\n",
        "print(train_mask.size())\n",
        "print(sum(train_mask))\n",
        "\n",
        "val_mask = (x.unsqueeze(0) == val_mask.unsqueeze(1)).all(dim = 2).any(dim = 0)\n",
        "print(val_mask)\n",
        "print(val_mask.size())\n",
        "print(sum(val_mask))\n",
        "\n",
        "test_mask = (x.unsqueeze(0) == test_mask.unsqueeze(1)).all(dim = 2 ).any(dim = 0)\n",
        "print(test_mask)\n",
        "print(test_mask.size())\n",
        "print(sum(test_mask))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuuOMQ1_BjYj",
        "outputId": "db08a88a-cfac-418c-a7eb-64754e1b7a3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ True, False,  True,  True,  True,  True, False,  True, False,  True,\n",
            "         True, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "        False,  True,  True,  True,  True, False,  True,  True, False,  True,\n",
            "         True,  True,  True,  True,  True, False,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True, False, False,  True,  True,  True,  True,\n",
            "        False,  True,  True,  True,  True,  True,  True, False,  True,  True,\n",
            "         True, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True, False,  True,  True,  True, False, False,  True,  True,\n",
            "         True, False,  True, False,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True, False,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True, False,  True,  True, False, False,  True,\n",
            "         True, False,  True, False,  True, False,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "        False,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
            "         True,  True, False,  True,  True, False,  True,  True, False,  True])\n",
            "torch.Size([150])\n",
            "tensor(120)\n",
            "tensor([False, False, False, False, False, False,  True, False,  True, False,\n",
            "        False,  True, False, False, False, False, False, False, False, False,\n",
            "         True, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False,  True, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False,  True, False, False, False, False, False, False,\n",
            "        False, False,  True, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False,  True, False, False,\n",
            "        False,  True, False,  True, False,  True, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "         True, False, False, False, False, False, False, False,  True, False,\n",
            "        False, False,  True, False, False, False, False, False,  True, False])\n",
            "torch.Size([150])\n",
            "tensor(15)\n",
            "tensor([False,  True, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False,  True, False, False,  True, False,\n",
            "        False, False, False, False, False,  True, False, False, False, False,\n",
            "        False, False, False, False, False,  True, False, False, False, False,\n",
            "         True, False, False, False, False, False, False,  True, False, False,\n",
            "        False,  True, False, False, False, False, False, False, False, False,\n",
            "        False, False,  True, False, False, False,  True,  True, False, False,\n",
            "        False,  True, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False,  True, False, False, False,  True, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False,  True, False, False, False, False])\n",
            "torch.Size([150])\n",
            "tensor(15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## It is time to use p_link as attentions."
      ],
      "metadata": {
        "id": "Oxs1yyPlBoWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p_link = pd.read_csv('/gdrive/MyDrive/5classes_150.sim/p_links_150.csv', sep =',',header = None)\n",
        "p_link = p_link.astype(np.float32)\n",
        "p_link = torch.tensor(p_link.values)\n",
        "#p_link = p_link.to(torch.float32)\n",
        "print(p_link.size())\n",
        "print(p_link.dtype)\n",
        "print(p_link.type())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSLWZXmxBrnQ",
        "outputId": "85816a84-f5e8-4589-fb60-ee942136eae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([150, 150])\n",
            "torch.float32\n",
            "torch.FloatTensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now everything is ready to develop our GNNs."
      ],
      "metadata": {
        "id": "z_gOhrlFBw3K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install torch_geometric."
      ],
      "metadata": {
        "id": "GQgrIJcbB5z4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zT8-r3BZB3dz",
        "outputId": "69c9ac9a-15de-40df-9b91-b6dce63e746e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu118\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save data in order to use it."
      ],
      "metadata": {
        "id": "Apa9QwYIB-Ni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Data\n",
        "Data = Data(x = x, edge_index = edge_index, y = y, train_mask = train_mask, val_mask = val_mask, test_mask = test_mask)\n",
        "print(Data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvNG4Y2eCAHy",
        "outputId": "09f7cf6e-6da6-49f2-9ef7-c74c60acb40f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[150, 500], edge_index=[2, 954], y=[150], train_mask=[150], val_mask=[150], test_mask=[150])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_save_name = 'data.pt'\n",
        "path = F\"/gdrive/MyDrive/5classes_150.sim/{data_save_name}\"\n",
        "torch.save(Data.to_dict(), path)"
      ],
      "metadata": {
        "id": "JUyBmBG0CCBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_link_save_name = 'p_link.pt'\n",
        "path = F\"/gdrive/MyDrive/5classes_150.sim/{p_link_save_name}\"\n",
        "torch.save(p_link, path)"
      ],
      "metadata": {
        "id": "uSdalxEKCF25"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}