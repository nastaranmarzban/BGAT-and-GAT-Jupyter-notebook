{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Mount to gdrive to read data, adjacency matrix, p_link and labels. "
      ],
      "metadata": {
        "id": "7HS_3few3-FW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TwCsrV4IiB0-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be18ee96-c59f-4821-f692-1bff370648c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install pandas to read csv files from gdrive. Install torch and numpy which are packages that are needed durind coding."
      ],
      "metadata": {
        "id": "rPLFhxZt4B0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "1dLDJAB-iLEO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b50ce30-67e1-48b9-cb09-a3360cb4e2ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## It is time to prepare x, edge_index, y, train_mask and test_mask which are needed for PyG. \n"
      ],
      "metadata": {
        "id": "IzO2fLH94FVQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step1 (preparing x)**: Read multivariate dataset from gdrive and convert the type to what is needed in PyG."
      ],
      "metadata": {
        "id": "wnHSQIYv4Pn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = pd.read_csv('/gdrive/MyDrive/Cancer/cancer_t.csv', sep=',',header=None)\n",
        "x = x.astype(np.float32) #try to cast all DataFrame columns to specified numpy.dtype\n",
        "x = torch.tensor(x.values) #convert numpy.dtype to a tensor\n",
        "print(x.sum(dim = 1).unique().size()) #to see if there is a duplicate data in x or not\n",
        "print(x.dtype)\n",
        "print(x.type())\n",
        "print(x)\n",
        "print(x.size())"
      ],
      "metadata": {
        "id": "QFzUjTz_iOcA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0791ec48-b29d-4aab-f8bb-40d7961d671a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([80])\n",
            "torch.float32\n",
            "torch.FloatTensor\n",
            "tensor([[1.7990e+01, 1.0380e+01, 1.2280e+02,  ..., 2.6540e-01, 4.6010e-01,\n",
            "         1.1890e-01],\n",
            "        [2.0570e+01, 1.7770e+01, 1.3290e+02,  ..., 1.8600e-01, 2.7500e-01,\n",
            "         8.9020e-02],\n",
            "        [1.9690e+01, 2.1250e+01, 1.3000e+02,  ..., 2.4300e-01, 3.6130e-01,\n",
            "         8.7580e-02],\n",
            "        ...,\n",
            "        [1.3030e+01, 1.8420e+01, 8.2610e+01,  ..., 5.0130e-02, 1.9870e-01,\n",
            "         6.1690e-02],\n",
            "        [1.3080e+01, 1.5710e+01, 8.5630e+01,  ..., 7.2830e-02, 3.1840e-01,\n",
            "         8.1830e-02],\n",
            "        [9.5040e+00, 1.2440e+01, 6.0340e+01,  ..., 6.2270e-02, 2.4500e-01,\n",
            "         7.7730e-02]])\n",
            "torch.Size([80, 30])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step2 (preparing edge_index)**: Read adjacency matrix from gdrive and convert the type to what is needed in PyG. "
      ],
      "metadata": {
        "id": "A5QZv1jH4TVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import coo_matrix\n",
        "edge_index_csv = pd.read_csv('/gdrive/MyDrive/Cancer/adj_cancer.csv',sep=',',header=None)\n",
        "#print(edge_index_csv)\n",
        "edge_index_numpy_ndarry = edge_index_csv.values #convert xlsx file to numpy.ndarry\n",
        "edge_index_coo = coo_matrix(edge_index_numpy_ndarry) #convert symmetric matrix to coo_matrix\n",
        "print(edge_index_coo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTBxITsiA1WZ",
        "outputId": "29a7160f-97a9-4b5b-f8ab-5d47362da46c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 2)\t1\n",
            "  (0, 3)\t1\n",
            "  (0, 4)\t1\n",
            "  (0, 11)\t1\n",
            "  (0, 20)\t1\n",
            "  (0, 24)\t1\n",
            "  (0, 25)\t1\n",
            "  (0, 31)\t1\n",
            "  (0, 38)\t1\n",
            "  (0, 45)\t1\n",
            "  (0, 56)\t1\n",
            "  (0, 72)\t1\n",
            "  (0, 77)\t1\n",
            "  (1, 6)\t1\n",
            "  (1, 7)\t1\n",
            "  (1, 10)\t1\n",
            "  (1, 14)\t1\n",
            "  (1, 17)\t1\n",
            "  (1, 20)\t1\n",
            "  (1, 36)\t1\n",
            "  (1, 46)\t1\n",
            "  (1, 60)\t1\n",
            "  (1, 62)\t1\n",
            "  (1, 64)\t1\n",
            "  (1, 68)\t1\n",
            "  :\t:\n",
            "  (78, 35)\t1\n",
            "  (78, 48)\t1\n",
            "  (78, 56)\t1\n",
            "  (78, 64)\t1\n",
            "  (78, 65)\t1\n",
            "  (78, 76)\t1\n",
            "  (79, 5)\t1\n",
            "  (79, 10)\t1\n",
            "  (79, 15)\t1\n",
            "  (79, 16)\t1\n",
            "  (79, 17)\t1\n",
            "  (79, 35)\t1\n",
            "  (79, 36)\t1\n",
            "  (79, 43)\t1\n",
            "  (79, 45)\t1\n",
            "  (79, 46)\t1\n",
            "  (79, 47)\t1\n",
            "  (79, 52)\t1\n",
            "  (79, 58)\t1\n",
            "  (79, 61)\t1\n",
            "  (79, 62)\t1\n",
            "  (79, 70)\t1\n",
            "  (79, 72)\t1\n",
            "  (79, 74)\t1\n",
            "  (79, 76)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edge_index_numpy = np.vstack((edge_index_coo.row, edge_index_coo.col)) #convert coo_matrix to numpy.ndarray\n",
        "edge_index_torch_int32 = torch.from_numpy(edge_index_numpy) #convert numpy.ndarray to torch.int32\n",
        "edge_index = edge_index_torch_int32.to(torch.int64) #convert torch.int32 to torch.long\n",
        "print(edge_index)\n",
        "print(edge_index.dtype)\n",
        "print(edge_index.type())\n",
        "print(edge_index.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYJ84c9GB6Sx",
        "outputId": "e44ea0e7-977d-40a2-8dde-57980406fc5e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0,  0,  0,  ..., 79, 79, 79],\n",
            "        [ 2,  3,  4,  ..., 72, 74, 76]])\n",
            "torch.int64\n",
            "torch.LongTensor\n",
            "torch.Size([2, 872])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step3 (preparing y)**: Read labels from gdrive and convert the type to what is needed in PyG."
      ],
      "metadata": {
        "id": "nVyH8_T_4Xa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_csv = pd.read_csv('/gdrive/MyDrive/Cancer/labels_cancer.csv',sep=',',header=None)\n",
        "y = torch.tensor(labels_csv.values)\n",
        "y.resize_((80))\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBc9uPkcCE3K",
        "outputId": "4e2465c6-481a-43c8-e56c-e1fc48154f11"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step4 (preparing train_mask, test_mask)**: split x and y into train and test set."
      ],
      "metadata": {
        "id": "_-OZFSPf4bjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "main_mask, test_mask, y_main, y_test= train_test_split(x, y,  test_size = 48, random_state = 0, shuffle = True, stratify=y)\n",
        "train_mask, val_mask, y_train, y_val= train_test_split(main_mask, y_main,  test_size = 10, random_state = 0, shuffle = True, stratify = y_main)\n",
        "#train_mask = train_mask.to(torch.long)\n",
        "#test_mask = test_mask.to(torch.long)\n",
        "print(train_mask)\n",
        "print(test_mask)\n",
        "print(train_mask.size())\n",
        "print(val_mask.size())\n",
        "print(test_mask.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQsWIEzzCPbk",
        "outputId": "87f56a61-c576-4818-845e-83d345d9297b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.1760e+01, 2.1600e+01, 7.4720e+01, 4.2790e+02, 8.6370e-02, 4.9660e-02,\n",
            "         1.6570e-02, 1.1150e-02, 1.4950e-01, 5.8880e-02, 4.0620e-01, 1.2100e+00,\n",
            "         2.6350e+00, 2.8470e+01, 5.8570e-03, 9.7580e-03, 1.1680e-02, 7.4450e-03,\n",
            "         2.4060e-02, 1.7690e-03, 1.2980e+01, 2.5720e+01, 8.2980e+01, 5.1650e+02,\n",
            "         1.0850e-01, 8.6150e-02, 5.5230e-02, 3.7150e-02, 2.4330e-01, 6.5630e-02],\n",
            "        [1.0490e+01, 1.9290e+01, 6.7410e+01, 3.3610e+02, 9.9890e-02, 8.5780e-02,\n",
            "         2.9950e-02, 1.2010e-02, 2.2170e-01, 6.4810e-02, 3.5500e-01, 1.5340e+00,\n",
            "         2.3020e+00, 2.3130e+01, 7.5950e-03, 2.2190e-02, 2.8800e-02, 8.6140e-03,\n",
            "         2.7100e-02, 3.4510e-03, 1.1540e+01, 2.3310e+01, 7.4220e+01, 4.0280e+02,\n",
            "         1.2190e-01, 1.4860e-01, 7.9870e-02, 3.2030e-02, 2.8260e-01, 7.5520e-02],\n",
            "        [1.6020e+01, 2.3240e+01, 1.0270e+02, 7.9780e+02, 8.2060e-02, 6.6690e-02,\n",
            "         3.2990e-02, 3.3230e-02, 1.5280e-01, 5.6970e-02, 3.7950e-01, 1.1870e+00,\n",
            "         2.4660e+00, 4.0510e+01, 4.0290e-03, 9.2690e-03, 1.1010e-02, 7.5910e-03,\n",
            "         1.4600e-02, 3.0420e-03, 1.9190e+01, 3.3880e+01, 1.2380e+02, 1.1500e+03,\n",
            "         1.1810e-01, 1.5510e-01, 1.4590e-01, 9.9750e-02, 2.9480e-01, 8.4520e-02],\n",
            "        [1.5300e+01, 2.5270e+01, 1.0240e+02, 7.3240e+02, 1.0820e-01, 1.6970e-01,\n",
            "         1.6830e-01, 8.7510e-02, 1.9260e-01, 6.5400e-02, 4.3900e-01, 1.0120e+00,\n",
            "         3.4980e+00, 4.3500e+01, 5.2330e-03, 3.0570e-02, 3.5760e-02, 1.0830e-02,\n",
            "         1.7680e-02, 2.9670e-03, 2.0270e+01, 3.6710e+01, 1.4930e+02, 1.2690e+03,\n",
            "         1.6410e-01, 6.1100e-01, 6.3350e-01, 2.0240e-01, 4.0270e-01, 9.8760e-02],\n",
            "        [1.4540e+01, 2.7540e+01, 9.6730e+01, 6.5880e+02, 1.1390e-01, 1.5950e-01,\n",
            "         1.6390e-01, 7.3640e-02, 2.3030e-01, 7.0770e-02, 3.7000e-01, 1.0330e+00,\n",
            "         2.8790e+00, 3.2550e+01, 5.6070e-03, 4.2400e-02, 4.7410e-02, 1.0900e-02,\n",
            "         1.8570e-02, 5.4660e-03, 1.7460e+01, 3.7130e+01, 1.2410e+02, 9.4320e+02,\n",
            "         1.6780e-01, 6.5770e-01, 7.0260e-01, 1.7120e-01, 4.2180e-01, 1.3410e-01],\n",
            "        [1.3280e+01, 2.0280e+01, 8.7320e+01, 5.4520e+02, 1.0410e-01, 1.4360e-01,\n",
            "         9.8470e-02, 6.1580e-02, 1.9740e-01, 6.7820e-02, 3.7040e-01, 8.2490e-01,\n",
            "         2.4270e+00, 3.1330e+01, 5.0720e-03, 2.1470e-02, 2.1850e-02, 9.5600e-03,\n",
            "         1.7190e-02, 3.3170e-03, 1.7380e+01, 2.8000e+01, 1.1310e+02, 9.0720e+02,\n",
            "         1.5300e-01, 3.7240e-01, 3.6640e-01, 1.4920e-01, 3.7390e-01, 1.0270e-01],\n",
            "        [1.5780e+01, 1.7890e+01, 1.0360e+02, 7.8100e+02, 9.7100e-02, 1.2920e-01,\n",
            "         9.9540e-02, 6.6060e-02, 1.8420e-01, 6.0820e-02, 5.0580e-01, 9.8490e-01,\n",
            "         3.5640e+00, 5.4160e+01, 5.7710e-03, 4.0610e-02, 2.7910e-02, 1.2820e-02,\n",
            "         2.0080e-02, 4.1440e-03, 2.0420e+01, 2.7280e+01, 1.3650e+02, 1.2990e+03,\n",
            "         1.3960e-01, 5.6090e-01, 3.9650e-01, 1.8100e-01, 3.7920e-01, 1.0480e-01],\n",
            "        [1.3490e+01, 2.2300e+01, 8.6910e+01, 5.6100e+02, 8.7520e-02, 7.6980e-02,\n",
            "         4.7510e-02, 3.3840e-02, 1.8090e-01, 5.7180e-02, 2.3380e-01, 1.3530e+00,\n",
            "         1.7350e+00, 2.0200e+01, 4.4550e-03, 1.3820e-02, 2.0950e-02, 1.1840e-02,\n",
            "         1.6410e-02, 1.9560e-03, 1.5150e+01, 3.1820e+01, 9.9000e+01, 6.9880e+02,\n",
            "         1.1620e-01, 1.7110e-01, 2.2820e-01, 1.2820e-01, 2.8710e-01, 6.9170e-02],\n",
            "        [1.3270e+01, 1.4760e+01, 8.4740e+01, 5.5170e+02, 7.3550e-02, 5.0550e-02,\n",
            "         3.2610e-02, 2.6480e-02, 1.3860e-01, 5.3180e-02, 4.0570e-01, 1.1530e+00,\n",
            "         2.7010e+00, 3.6350e+01, 4.4810e-03, 1.0380e-02, 1.3580e-02, 1.0820e-02,\n",
            "         1.0690e-02, 1.4350e-03, 1.6360e+01, 2.2350e+01, 1.0450e+02, 8.3060e+02,\n",
            "         1.0060e-01, 1.2380e-01, 1.3500e-01, 1.0010e-01, 2.0270e-01, 6.2060e-02],\n",
            "        [2.0290e+01, 1.4340e+01, 1.3510e+02, 1.2970e+03, 1.0030e-01, 1.3280e-01,\n",
            "         1.9800e-01, 1.0430e-01, 1.8090e-01, 5.8830e-02, 7.5720e-01, 7.8130e-01,\n",
            "         5.4380e+00, 9.4440e+01, 1.1490e-02, 2.4610e-02, 5.6880e-02, 1.8850e-02,\n",
            "         1.7560e-02, 5.1150e-03, 2.2540e+01, 1.6670e+01, 1.5220e+02, 1.5750e+03,\n",
            "         1.3740e-01, 2.0500e-01, 4.0000e-01, 1.6250e-01, 2.3640e-01, 7.6780e-02],\n",
            "        [1.3540e+01, 1.4360e+01, 8.7460e+01, 5.6630e+02, 9.7790e-02, 8.1290e-02,\n",
            "         6.6640e-02, 4.7810e-02, 1.8850e-01, 5.7660e-02, 2.6990e-01, 7.8860e-01,\n",
            "         2.0580e+00, 2.3560e+01, 8.4620e-03, 1.4600e-02, 2.3870e-02, 1.3150e-02,\n",
            "         1.9800e-02, 2.3000e-03, 1.5110e+01, 1.9260e+01, 9.9700e+01, 7.1120e+02,\n",
            "         1.4400e-01, 1.7730e-01, 2.3900e-01, 1.2880e-01, 2.9770e-01, 7.2590e-02],\n",
            "        [8.8880e+00, 1.4640e+01, 5.8790e+01, 2.4400e+02, 9.7830e-02, 1.5310e-01,\n",
            "         8.6060e-02, 2.8720e-02, 1.9020e-01, 8.9800e-02, 5.2620e-01, 8.5220e-01,\n",
            "         3.1680e+00, 2.5440e+01, 1.7210e-02, 9.3680e-02, 5.6710e-02, 1.7660e-02,\n",
            "         2.5410e-02, 2.1930e-02, 9.7330e+00, 1.5670e+01, 6.2560e+01, 2.8440e+02,\n",
            "         1.2070e-01, 2.4360e-01, 1.4340e-01, 4.7860e-02, 2.2540e-01, 1.0840e-01],\n",
            "        [1.7020e+01, 2.3980e+01, 1.1280e+02, 8.9930e+02, 1.1970e-01, 1.4960e-01,\n",
            "         2.4170e-01, 1.2030e-01, 2.2480e-01, 6.3820e-02, 6.0090e-01, 1.3980e+00,\n",
            "         3.9990e+00, 6.7780e+01, 8.2680e-03, 3.0820e-02, 5.0420e-02, 1.1120e-02,\n",
            "         2.1020e-02, 3.8540e-03, 2.0880e+01, 3.2090e+01, 1.3610e+02, 1.3440e+03,\n",
            "         1.6340e-01, 3.5590e-01, 5.5880e-01, 1.8470e-01, 3.5300e-01, 8.4820e-02],\n",
            "        [1.7140e+01, 1.6400e+01, 1.1600e+02, 9.1270e+02, 1.1860e-01, 2.2760e-01,\n",
            "         2.2290e-01, 1.4010e-01, 3.0400e-01, 7.4130e-02, 1.0460e+00, 9.7600e-01,\n",
            "         7.2760e+00, 1.1140e+02, 8.0290e-03, 3.7990e-02, 3.7320e-02, 2.3970e-02,\n",
            "         2.3080e-02, 7.4440e-03, 2.2250e+01, 2.1400e+01, 1.5240e+02, 1.4610e+03,\n",
            "         1.5450e-01, 3.9490e-01, 3.8530e-01, 2.5500e-01, 4.0660e-01, 1.0590e-01],\n",
            "        [1.3080e+01, 1.5710e+01, 8.5630e+01, 5.2000e+02, 1.0750e-01, 1.2700e-01,\n",
            "         4.5680e-02, 3.1100e-02, 1.9670e-01, 6.8110e-02, 1.8520e-01, 7.4770e-01,\n",
            "         1.3830e+00, 1.4670e+01, 4.0970e-03, 1.8980e-02, 1.6980e-02, 6.4900e-03,\n",
            "         1.6780e-02, 2.4250e-03, 1.4500e+01, 2.0490e+01, 9.6090e+01, 6.3050e+02,\n",
            "         1.3120e-01, 2.7760e-01, 1.8900e-01, 7.2830e-02, 3.1840e-01, 8.1830e-02],\n",
            "        [1.9270e+01, 2.6470e+01, 1.2790e+02, 1.1620e+03, 9.4010e-02, 1.7190e-01,\n",
            "         1.6570e-01, 7.5930e-02, 1.8530e-01, 6.2610e-02, 5.5580e-01, 6.0620e-01,\n",
            "         3.5280e+00, 6.8170e+01, 5.0150e-03, 3.3180e-02, 3.4970e-02, 9.6430e-03,\n",
            "         1.5430e-02, 3.8960e-03, 2.4150e+01, 3.0900e+01, 1.6140e+02, 1.8130e+03,\n",
            "         1.5090e-01, 6.5900e-01, 6.0910e-01, 1.7850e-01, 3.6720e-01, 1.1230e-01],\n",
            "        [1.2000e+01, 1.5650e+01, 7.6950e+01, 4.4330e+02, 9.7230e-02, 7.1650e-02,\n",
            "         4.1510e-02, 1.8630e-02, 2.0790e-01, 5.9680e-02, 2.2710e-01, 1.2550e+00,\n",
            "         1.4410e+00, 1.6160e+01, 5.9690e-03, 1.8120e-02, 2.0070e-02, 7.0270e-03,\n",
            "         1.9720e-02, 2.6070e-03, 1.3670e+01, 2.4900e+01, 8.7780e+01, 5.6790e+02,\n",
            "         1.3770e-01, 2.0030e-01, 2.2670e-01, 7.6320e-02, 3.3790e-01, 7.9240e-02],\n",
            "        [1.9690e+01, 2.1250e+01, 1.3000e+02, 1.2030e+03, 1.0960e-01, 1.5990e-01,\n",
            "         1.9740e-01, 1.2790e-01, 2.0690e-01, 5.9990e-02, 7.4560e-01, 7.8690e-01,\n",
            "         4.5850e+00, 9.4030e+01, 6.1500e-03, 4.0060e-02, 3.8320e-02, 2.0580e-02,\n",
            "         2.2500e-02, 4.5710e-03, 2.3570e+01, 2.5530e+01, 1.5250e+02, 1.7090e+03,\n",
            "         1.4440e-01, 4.2450e-01, 4.5040e-01, 2.4300e-01, 3.6130e-01, 8.7580e-02],\n",
            "        [1.4640e+01, 1.5240e+01, 9.5770e+01, 6.5190e+02, 1.1320e-01, 1.3390e-01,\n",
            "         9.9660e-02, 7.0640e-02, 2.1160e-01, 6.3460e-02, 5.1150e-01, 7.3720e-01,\n",
            "         3.8140e+00, 4.2760e+01, 5.5080e-03, 4.4120e-02, 4.4360e-02, 1.6230e-02,\n",
            "         2.4270e-02, 4.8410e-03, 1.6340e+01, 1.8240e+01, 1.0940e+02, 8.0360e+02,\n",
            "         1.2770e-01, 3.0890e-01, 2.6040e-01, 1.3970e-01, 3.1510e-01, 8.4730e-02],\n",
            "        [1.8630e+01, 2.5110e+01, 1.2480e+02, 1.0880e+03, 1.0640e-01, 1.8870e-01,\n",
            "         2.3190e-01, 1.2440e-01, 2.1830e-01, 6.1970e-02, 8.3070e-01, 1.4660e+00,\n",
            "         5.5740e+00, 1.0500e+02, 6.2480e-03, 3.3740e-02, 5.1960e-02, 1.1580e-02,\n",
            "         2.0070e-02, 4.5600e-03, 2.3150e+01, 3.4010e+01, 1.6050e+02, 1.6700e+03,\n",
            "         1.4910e-01, 4.2570e-01, 6.1330e-01, 1.8480e-01, 3.4440e-01, 9.7820e-02],\n",
            "        [1.4620e+01, 2.4020e+01, 9.4570e+01, 6.6270e+02, 8.9740e-02, 8.6060e-02,\n",
            "         3.1020e-02, 2.9570e-02, 1.6850e-01, 5.8660e-02, 3.7210e-01, 1.1110e+00,\n",
            "         2.2790e+00, 3.3760e+01, 4.8680e-03, 1.8180e-02, 1.1210e-02, 8.6060e-03,\n",
            "         2.0850e-02, 2.8930e-03, 1.6110e+01, 2.9110e+01, 1.0290e+02, 8.0370e+02,\n",
            "         1.1150e-01, 1.7660e-01, 9.1890e-02, 6.9460e-02, 2.5220e-01, 7.2460e-02],\n",
            "        [9.0290e+00, 1.7330e+01, 5.8790e+01, 2.5050e+02, 1.0660e-01, 1.4130e-01,\n",
            "         3.1300e-01, 4.3750e-02, 2.1110e-01, 8.0460e-02, 3.2740e-01, 1.1940e+00,\n",
            "         1.8850e+00, 1.7670e+01, 9.5490e-03, 8.6060e-02, 3.0380e-01, 3.3220e-02,\n",
            "         4.1970e-02, 9.5590e-03, 1.0310e+01, 2.2650e+01, 6.5500e+01, 3.2470e+02,\n",
            "         1.4820e-01, 4.3650e-01, 1.2520e+00, 1.7500e-01, 4.2280e-01, 1.1750e-01]])\n",
            "tensor([[1.2310e+01, 1.6520e+01, 7.9190e+01,  ..., 8.6600e-02, 2.6180e-01,\n",
            "         7.6090e-02],\n",
            "        [1.2450e+01, 1.5700e+01, 8.2570e+01,  ..., 1.7410e-01, 3.9850e-01,\n",
            "         1.2440e-01],\n",
            "        [1.1450e+01, 2.0970e+01, 7.3810e+01,  ..., 6.1270e-02, 2.7620e-01,\n",
            "         8.8510e-02],\n",
            "        ...,\n",
            "        [1.3710e+01, 2.0830e+01, 9.0200e+01,  ..., 1.5560e-01, 3.1960e-01,\n",
            "         1.1510e-01],\n",
            "        [1.9070e+01, 2.4810e+01, 1.2830e+02,  ..., 2.4930e-01, 4.6700e-01,\n",
            "         1.0380e-01],\n",
            "        [9.5040e+00, 1.2440e+01, 6.0340e+01,  ..., 6.2270e-02, 2.4500e-01,\n",
            "         7.7730e-02]])\n",
            "torch.Size([22, 30])\n",
            "torch.Size([10, 30])\n",
            "torch.Size([48, 30])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## To see how many percent of data belong to each class."
      ],
      "metadata": {
        "id": "bmdK4KOZ4nGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels, counts = np.unique(y_train, return_counts = True)\n",
        "print(counts/float(len(y_train)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOzc0fefC5ip",
        "outputId": "1d9320eb-48be-4862-fc59-88c112b89032"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5 0.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels, counts = np.unique(y_test, return_counts = True)\n",
        "print(counts/float(len(y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoZQtVSsC8aE",
        "outputId": "b66c8e14-976c-49c5-b766-a0fc9ad4a80b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5 0.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels, counts = np.unique(y_val, return_counts = True)\n",
        "print(counts/float(len(y_val)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC2HeDCjC_sT",
        "outputId": "a95bef9c-ef67-4b62-fcae-7c87c83eca32"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5 0.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing train_mask and test_mask based on PyG."
      ],
      "metadata": {
        "id": "K1QNE6Ir4qbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_mask = (x.unsqueeze(0) == train_mask.unsqueeze(1)).all(dim=2).any(dim=0)\n",
        "print(train_mask)\n",
        "print(train_mask.size())\n",
        "print(sum(train_mask))\n",
        "\n",
        "val_mask = (x.unsqueeze(0) == val_mask.unsqueeze(1)).all(dim=2).any(dim=0)\n",
        "print(val_mask)\n",
        "print(val_mask.size())\n",
        "print(sum(val_mask))\n",
        "\n",
        "test_mask = (x.unsqueeze(0) == test_mask.unsqueeze(1)).all(dim=2).any(dim=0)\n",
        "print(test_mask)\n",
        "print(test_mask.size())\n",
        "print(sum(test_mask))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coKLgribDHK5",
        "outputId": "3c27dfb3-78ec-491a-8079-b0f2728d9fb8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([False, False,  True, False,  True, False, False, False, False, False,\n",
            "         True,  True, False, False, False,  True, False, False, False, False,\n",
            "        False, False,  True, False, False,  True, False,  True, False,  True,\n",
            "         True, False, False, False, False, False, False, False, False,  True,\n",
            "        False, False,  True,  True, False, False, False, False, False, False,\n",
            "        False, False, False, False,  True, False,  True, False, False, False,\n",
            "        False, False,  True, False,  True,  True,  True, False, False, False,\n",
            "        False, False, False, False,  True, False,  True, False,  True, False])\n",
            "torch.Size([80])\n",
            "tensor(22)\n",
            "tensor([False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False,  True, False,\n",
            "         True, False, False, False, False, False, False, False,  True, False,\n",
            "        False, False, False, False, False,  True, False,  True, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False,  True,  True, False, False, False, False,  True, False,\n",
            "        False, False, False, False, False, False, False,  True, False, False,\n",
            "        False, False, False,  True, False, False, False, False, False, False])\n",
            "torch.Size([80])\n",
            "tensor(10)\n",
            "tensor([ True,  True, False,  True, False,  True,  True,  True,  True,  True,\n",
            "        False, False,  True,  True,  True, False,  True,  True, False,  True,\n",
            "        False,  True, False,  True,  True, False,  True, False, False, False,\n",
            "        False,  True,  True,  True,  True, False,  True, False,  True, False,\n",
            "         True,  True, False, False,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True, False, False, False,  True, False,  True, False,  True,\n",
            "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
            "         True,  True,  True, False, False,  True, False,  True, False,  True])\n",
            "torch.Size([80])\n",
            "tensor(48)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## It is time to use p_link as attentions."
      ],
      "metadata": {
        "id": "bxFN1cEX4vMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p_link = pd.read_csv('/gdrive/MyDrive/Cancer/p_links_cancer.csv', sep=',',header=None)\n",
        "p_link = p_link.astype(np.float32)\n",
        "p_link = torch.tensor(p_link.values)\n",
        "#p_link = p_link.to(torch.float32)\n",
        "print(p_link.size())\n",
        "print(p_link.dtype)\n",
        "print(p_link.type())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j68hpRhXDKsE",
        "outputId": "6f058073-aa44-4fa6-e7fd-252653931d6e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([80, 80])\n",
            "torch.float32\n",
            "torch.FloatTensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now everything is ready to develop our GNNs."
      ],
      "metadata": {
        "id": "5F7SiY9B4x4S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install torch_geometric."
      ],
      "metadata": {
        "id": "XO1aw0sf4-EA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMxTd2-aDWSy",
        "outputId": "cdb36ba4-ad81-440d-e5b5-0b78796a679d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.0+cu116\n",
            "\u001b[K     |████████████████████████████████| 9.4 MB 5.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 280 kB 4.4 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Data\n",
        "Data = Data(x=x, edge_index=edge_index, y = y, train_mask = train_mask, val_mask = val_mask, test_mask = test_mask)\n",
        "print(Data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVnChauYDZ67",
        "outputId": "380e8dfd-3fef-4957-d46c-844edbd485ac"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[80, 30], edge_index=[2, 872], y=[80], train_mask=[80], val_mask=[80], test_mask=[80])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save data in order to use it. "
      ],
      "metadata": {
        "id": "tmm0Yua642Hu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_save_name = 'cancer.pt'  \n",
        "path = F\"/gdrive/MyDrive/Cancer/{data_save_name}\" \n",
        "torch.save(Data.to_dict(), path)"
      ],
      "metadata": {
        "id": "4b7kx_VpDgrS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_link_save_name = 'p_links_cancer.pt'  \n",
        "path = F\"/gdrive/MyDrive/Cancer/{p_link_save_name}\" \n",
        "torch.save(p_link, path)"
      ],
      "metadata": {
        "id": "u65UcXdSEmmz"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}